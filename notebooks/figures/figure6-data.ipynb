{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of data for Figure 6 (Molina, Gagne, and Prein; under review)\n",
    "\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from configpaths import dlproj_main, current_dl_models, future_dl_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = '25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_negs(data):\n",
    "    \"\"\"\n",
    "    Function to convert negative data to 0.0 for plot range 0-to-1.\n",
    "    \"\"\"\n",
    "    data[data<0] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all current, future, and outlier PFI results for the 20 variables including performance diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_current={}\n",
    "for var in range(20):\n",
    "    path = f'{current_dl_models}/model25/scalar_results_nomask_model{model_num}_random*_pfivar{var}_perm*.csv'\n",
    "    files = glob.glob(path)\n",
    "    li = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "    files_current[var] = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "files_future={}\n",
    "for var in range(20):\n",
    "    path = f'{future_dl_models}/scalar_results_nomask_model{model_num}_random*_pfivar{var}_perm*.csv'\n",
    "    files = glob.glob(path)\n",
    "    li = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "    files_future[var] = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "files_out={}\n",
    "for var in range(20):\n",
    "    path = f'{future_dl_models}/scalar_outresults_nomask_model{model_num}_random1_pfivar{var}_perm*.csv'\n",
    "    files = glob.glob(path)\n",
    "    li = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "    files_out[var] = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all original error metrics for performance diagrams without permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for rndm in range(5):\n",
    "    filename = f'{current_dl_models}/model25/scalar_results_nomask_model{model_num}_random{rndm+1}.csv'\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "orig_c_r1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "li = []\n",
    "for rndm in range(5):\n",
    "    filename = f'{future_dl_models}/scalar_results_nomask_model{model_num}_random{rndm+1}.csv'\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "orig_f_r1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "filename = f'{future_dl_models}/scalar_outresults_nomask_model{model_num}_random1.csv'\n",
    "orig_o_r1 = pd.read_csv(filename, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all current, future, and outlier PFI results for the 20 variables including attributes diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_current={}\n",
    "for var in range(20):\n",
    "    path = f'{current_dl_models}/model25/bss_scalar_results_nomask_model{model_num}_random*_0.05_pfivar{var}_perm*.csv'\n",
    "    files = glob.glob(path)\n",
    "    li = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "    bss_current[var] = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "bss_future={}\n",
    "for var in range(20):\n",
    "    path = f'{future_dl_models}/bss_scalar_results_nomask_model{model_num}_random*_0.05_pfivar{var}_perm*.csv'\n",
    "    files = glob.glob(path)\n",
    "    li = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "    bss_future[var] = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "bss_out={}\n",
    "for var in range(20):\n",
    "    path = f'{future_dl_models}/bss_scalar_outresults_nomask_model{model_num}_random1_0.1_pfivar{var}_perm*.csv'\n",
    "    files = glob.glob(path)\n",
    "    li = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "    bss_out[var] = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all original error metrics for attributes diagrams without permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for rndm in range(5):\n",
    "    filename = f'{current_dl_models}/model25/bss_scalar_results_nomask_model{model_num}_random{rndm+1}_0.05.csv'\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "bssorig_c_r1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "li = []\n",
    "for rndm in range(5):\n",
    "    filename = f'{future_dl_models}/bss_scalar_results_nomask_model{model_num}_random{rndm+1}_0.05.csv'\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "bssorig_f_r1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "filename = f'{future_dl_models}/bss_scalar_outresults_nomask_model{model_num}_random1_0.1.csv'\n",
    "bssorig_o_r1 = pd.read_csv(filename, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble the arrays with change in error data for box and whisker plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_current_ = no_negs(\n",
    "    np.array([orig_c_r1[\"AUC\"].mean()-files_current[0][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[1][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[2][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[3][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[4][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[5][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[6][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[7][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[8][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[9][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[10][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[11][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[12][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[13][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[14][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[15][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[16][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[17][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[18][\"AUC\"].values,\n",
    "                         orig_c_r1[\"AUC\"].mean()-files_current[19][\"AUC\"].values]))\n",
    "\n",
    "csi_current_ = no_negs(\n",
    "    np.array([orig_c_r1[\"CSI\"].mean()-files_current[0][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[1][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[2][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[3][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[4][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[5][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[6][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[7][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[8][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[9][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[10][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[11][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[12][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[13][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[14][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[15][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[16][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[17][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[18][\"CSI\"].values,\n",
    "                         orig_c_r1[\"CSI\"].mean()-files_current[19][\"CSI\"].values]))\n",
    "\n",
    "bss_current_ = no_negs(\n",
    "    np.array([bssorig_c_r1[\"BSS\"].mean()-bss_current[0][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[1][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[2][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[3][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[4][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[5][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[6][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[7][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[8][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[9][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[10][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[11][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[12][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[13][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[14][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[15][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[16][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[17][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[18][\"BSS\"].values,\n",
    "                         bssorig_c_r1[\"BSS\"].mean()-bss_current[19][\"BSS\"].values]))\n",
    "\n",
    "auc_future_ = no_negs(\n",
    "    np.array([ orig_f_r1[\"AUC\"].mean()-files_future[0][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[1][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[2][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[3][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[4][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[5][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[6][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[7][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[8][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[9][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[10][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[11][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[12][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[13][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[14][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[15][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[16][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[17][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[18][\"AUC\"].values,\n",
    "                         orig_f_r1[\"AUC\"].mean()-files_future[19][\"AUC\"].values]))\n",
    "\n",
    "csi_future_ = no_negs(\n",
    "    np.array([ orig_f_r1[\"CSI\"].mean()-files_future[0][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[1][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[2][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[3][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[4][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[5][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[6][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[7][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[8][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[9][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[10][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[11][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[12][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[13][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[14][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[15][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[16][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[17][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[18][\"CSI\"].values,\n",
    "                         orig_f_r1[\"CSI\"].mean()-files_future[19][\"CSI\"].values]))\n",
    "\n",
    "bss_future_ = no_negs(\n",
    "    np.array([ bssorig_f_r1[\"BSS\"].mean()-bss_future[0][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[1][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[2][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[3][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[4][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[5][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[6][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[7][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[8][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[9][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[10][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[11][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[12][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[13][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[14][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[15][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[16][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[17][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[18][\"BSS\"].values,\n",
    "                         bssorig_f_r1[\"BSS\"].mean()-bss_future[19][\"BSS\"].values]))\n",
    "\n",
    "auc_outlier_ = no_negs(\n",
    "    np.array([orig_o_r1[\"AUC\"].mean()-files_out[0][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[1][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[2][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[3][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[4][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[5][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[6][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[7][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[8][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[9][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[10][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[11][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[12][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[13][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[14][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[15][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[16][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[17][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[18][\"AUC\"].values,\n",
    "                         orig_o_r1[\"AUC\"].mean()-files_out[19][\"AUC\"].values]))\n",
    "\n",
    "csi_outlier_ = no_negs(\n",
    "    np.array([orig_o_r1[\"CSI\"].mean()-files_out[0][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[1][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[2][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[3][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[4][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[5][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[6][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[7][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[8][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[9][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[10][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[11][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[12][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[13][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[14][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[15][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[16][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[17][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[18][\"CSI\"].values,\n",
    "                         orig_o_r1[\"CSI\"].mean()-files_out[19][\"CSI\"].values]))\n",
    "\n",
    "bss_outlier_ = no_negs(\n",
    "    np.array([bssorig_o_r1[\"BSS\"].mean()-bss_out[0][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[1][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[2][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[3][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[4][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[5][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[6][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[7][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[8][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[9][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[10][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[11][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[12][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[13][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[14][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[15][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[16][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[17][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[18][\"BSS\"].values,\n",
    "                         bssorig_o_r1[\"BSS\"].mean()-bss_out[19][\"BSS\"].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = xr.Dataset({\n",
    "                'auc_current_': (['a','b'], auc_current_),\n",
    "                'csi_current_': (['a','b'], csi_current_),\n",
    "                'bss_current_': (['a','b'], bss_current_),\n",
    "\n",
    "                'auc_future_': (['a','b'], auc_future_[:,:-5]),\n",
    "                'csi_future_': (['a','b'], csi_future_[:,:-5]),\n",
    "                'bss_future_': (['a','b'], bss_future_[:,:-5]),\n",
    "\n",
    "                'auc_outlier_': (['a','c'], auc_outlier_[:,:-1]),\n",
    "                'csi_outlier_': (['a','c'], csi_outlier_[:,:-1]),\n",
    "                'bss_outlier_': (['a','c'], bss_outlier_[:,:-1]),   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save.to_netcdf(f'{dlproj_main}/model{model_num}_pfidata.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-python-tutorial]",
   "language": "python",
   "name": "conda-env-miniconda3-python-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
